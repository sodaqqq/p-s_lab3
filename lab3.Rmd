---
title: "LAB 3"
output: html_notebook
---

# Lab assignment 3

## Team

*Ostap Kostiuk, Anastasia Yablunovska, Sofiia Vitchynkina*

## Work distribuition

**Task 1** - Sofiia Vitchynkina\
**Task 2** - Anastasia Yablunovska\
**Task 3** - Ostap Kostiuk

# Task 1

task ...

solution ...

# Task 2

**Task**: 

In this task, we study the construction of confidence intervals for the parameter θ of a Poisson distribution X∼Pois(θ).
The goal is to verify empirically that the confidence intervals constructed using methods (2)–(4) from Problem 1 indeed contain the true parameter with probability approximately equal to the nominal confidence level 1−a.
We also compare the precision of these intervals by analysing their average lengths.
For our team, the ID number is 16

**Solution**:


```{r}
set.seed(16)

# True parameter value
id_num <- 16
theta_true <- id_num / 10

cat("True parameter theta:", theta_true, "\n")

n_demo <- 50
M_demo <- 5000
sample_means_demo <- replicate(M_demo, mean(rpois(n_demo, lambda = theta_true)))
hist(sample_means_demo,
breaks = 40,
main = "Distribution of Sample Means (n = 50)",
xlab = "Sample Mean",
col = "lightblue",
border = "white")

```
Before constructing confidence intervals, we visualize the empirical distribution of the sample mean for n=50.
As expected from the central limit theorem, the distribution is approximately normal, which supports the use of normal and t-based approximations in the following methods.


## Method 2: Normal Approximation with Known Variance

For Poisson distribution P(θ), we have E[X] = θ and Var(X) = θ.

The Z-statistic is:
$$Z = \frac{\sqrt{n}(\bar{X} - \theta)}{\sqrt{\theta}} \sim N(0,1)$$

From this we get:
$$P(|\bar{X} - \theta| \leq z_\beta \sqrt{\theta/n}) = 2\beta - 1$$

The confidence interval (uses unknown θ) is:
$$\bar{X} \pm z_\beta \sqrt{\theta/n}$$

```{r}
method2_ci <- function(sample_mean, theta_true, n, alpha) {
  z_beta <- qnorm(1 - alpha/2)
  half_width <- z_beta * sqrt(theta_true / n)
  lower <- sample_mean - half_width
  upper <- sample_mean + half_width
  return(c(lower, upper))
}
```


## Method 3: Normal Approximation Solving for θ

Solving the inequality $|\bar{X} - \theta| \leq z_\beta \sqrt{\theta/n}$ for θ gives a practical CI that doesn't depend on θ:

$$\frac{(\bar{X} + z_\beta^2/(2n)) \pm z_\beta\sqrt{\bar{X}/n + z_\beta^2/(4n^2)}}{1 + z_\beta^2/n}$$

```{r}
method3_ci <- function(sample_mean, n, alpha) {
  z <- qnorm(1 - alpha/2)
  z_sq <- z^2
  
  a <- 1
  b <- -(2 * sample_mean + z_sq / n)
  c <- sample_mean^2
  
  discriminant <- b^2 - 4 * a * c
  lower <- (-b - sqrt(discriminant)) / (2 * a)
  upper <- (-b + sqrt(discriminant)) / (2 * a)
  
  return(c(lower, upper))
}
```


## Method 4: Student t-Distribution (with Sample Variance)

Using sample variance to estimate θ and applying t-distribution:
$$\bar{X} \pm t_{n-1, \beta} \frac{s}{\sqrt{n}}$$

where $s^2$ is the sample variance.

```{r}
method4_ci <- function(data, alpha) {
  n <- length(data)
  sample_mean <- mean(data)
  sample_sd <- sd(data)
  
  t_val <- qt(1 - alpha/2, df = n - 1)
  half_width <- t_val * sample_sd / sqrt(n)
  
  lower <- sample_mean - half_width
  upper <- sample_mean + half_width
  
  return(c(lower, upper))
}
```


## (a) Verification of Coverage Probability

```{r}
M <- 10000
sample_sizes <- c(10, 30, 50, 100, 500)
alphas <- c(0.1, 0.05, 0.01)

results <- data.frame()

for (alpha in alphas) {
  conf_level <- 1 - alpha
  
  for (n in sample_sizes) {
    samples_matrix <- matrix(rpois(M * n, lambda = theta_true), nrow = M)
    sample_means <- rowMeans(samples_matrix)
    
    coverage_m2 <- 0
    lengths_m2 <- numeric(M)
    
    coverage_m3 <- 0
    lengths_m3 <- numeric(M)
    
    coverage_m4 <- 0
    lengths_m4 <- numeric(M)
    
    for (i in 1:M) {
      ci2 <- method2_ci(sample_means[i], theta_true, n, alpha)
      coverage_m2 <- coverage_m2 + (ci2[1] <= theta_true & theta_true <= ci2[2])
      lengths_m2[i] <- ci2[2] - ci2[1]
      
      ci3 <- method3_ci(sample_means[i], n, alpha)
      coverage_m3 <- coverage_m3 + (ci3[1] <= theta_true & theta_true <= ci3[2])
      lengths_m3[i] <- ci3[2] - ci3[1]
      
      ci4 <- method4_ci(samples_matrix[i, ], alpha)
      coverage_m4 <- coverage_m4 + (ci4[1] <= theta_true & theta_true <= ci4[2])
      lengths_m4[i] <- ci4[2] - ci4[1]
    }
    
    results <- rbind(results, data.frame(
      alpha = alpha,
      conf_level = conf_level,
      n = n,
      method = "Method 2 (Known θ)",
      coverage = coverage_m2 / M,
      mean_length = mean(lengths_m2),
      median_length = median(lengths_m2)
    ))
    
    results <- rbind(results, data.frame(
      alpha = alpha,
      conf_level = conf_level,
      n = n,
      method = "Method 3 (Solved)",
      coverage = coverage_m3 / M,
      mean_length = mean(lengths_m3),
      median_length = median(lengths_m3)
    ))
    
    results <- rbind(results, data.frame(
      alpha = alpha,
      conf_level = conf_level,
      n = n,
      method = "Method 4 (t-dist)",
      coverage = coverage_m4 / M,
      mean_length = mean(lengths_m4),
      median_length = median(lengths_m4)
    ))
  }
}

print(results)
```


## (b) Comparison of Precision (Lengths)

```{r}
library(ggplot2)

ggplot(results, aes(x = n, y = coverage, color = method, linetype = method)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  geom_hline(aes(yintercept = conf_level), linetype = "dashed", color = "black") +
  facet_wrap(~ conf_level, labeller = label_both) +
  labs(
    title = "Coverage Probability vs Sample Size",
    subtitle = paste("True θ =", theta_true),
    x = "Sample Size (n)",
    y = "Empirical Coverage Probability",
    color = "Method",
    linetype = "Method"
  ) +
  theme_bw() +
  theme(legend.position = "bottom")

ggplot(results, aes(x = n, y = mean_length, color = method, linetype = method)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  facet_wrap(~ conf_level, labeller = label_both, scales = "free_y") +
  labs(
    title = "Mean Confidence Interval Length vs Sample Size",
    subtitle = paste("True θ =", theta_true),
    x = "Sample Size (n)",
    y = "Mean CI Length",
    color = "Method",
    linetype = "Method"
  ) +
  theme_bw() +
  theme(legend.position = "bottom")
```


## (c) Recommendation

**Summary of Results**:

```{r}
summary_alpha_05 <- results[results$alpha == 0.05, ]

cat("Summary for α = 0.05 (95% confidence level):\n\n")

for (n_val in unique(summary_alpha_05$n)) {
  cat("Sample size n =", n_val, ":\n")
  subset_data <- summary_alpha_05[summary_alpha_05$n == n_val, ]
  print(subset_data[, c("method", "coverage", "mean_length")])
  cat("\n")
}
```

**Analysis**:

1. **Method 2 (Known θ)**: 
   - This method uses the true value of θ, which is not available in practice
   - It serves as a theoretical benchmark
   - Coverage probability should be closest to nominal level
   - Shortest CI length among all methods

2. **Method 3 (Solved for θ)**:
   - Practical method that doesn't require knowing θ
   - Obtained by solving the inequality algebraically
   - Coverage probability may be slightly lower than nominal for small n
   - CI length is longer than Method 2 but still efficient

3. **Method 4 (Student t-distribution)**:
   - Most conservative and practical approach
   - Uses sample variance to estimate θ
   - Generally provides coverage ≥ nominal level
   - Wider intervals, especially for small n

**Recommendation**:

- **For small samples (n < 30)**: Use **Method 4** (Student t-distribution) as it provides more reliable coverage and accounts for estimation uncertainty in the variance.

- **For moderate to large samples (n ≥ 30)**: Use **Method 3** (solved CI) as it's practical, doesn't require knowing θ, and provides good coverage with reasonable precision.

- **Method 2** should not be used in practice since θ is unknown, but it's useful for theoretical comparisons.

**Conclusion**:

The simulation confirms that:
- All three methods achieve coverage probabilities close to the nominal level (1 - α) for sufficiently large samples
- As sample size increases, all methods converge in performance
- Method 4 is most robust for small samples but gives wider intervals
- Method 3 provides a good balance between coverage and precision for practical use

# Task 3

**Task**:

(a) write the code to find the variance for the dataset;

(b) find σ²ₙ and σ²ₙ₋₁ for n = 10, n = 50, n = 100, n = 1000;

(c) find the biases Bias(σ²ₙ) = E(σ²ₙ) − σ² and Bias(σ²ₙ₋₁) = E(σ²ₙ₋₁) − σ²;

(d) comment on the results for the different values of n;

(e) derive analytically the expected value of each estimator E(σ²ₙ) and E(σ²ₙ₋₁);

(f) using the expected values found above, show mathematically what of the above two estimators are unbiased;

(g) comment on the results behind theoretical and practical tasks.

**Solution**:

**(a)**

```{r}
set.seed(42)
n <- 5000
mu <- 10
sigma_squared <- 4
sigma <- sqrt(sigma_squared)
dataset <- rnorm(n, mean = mu, sd = sigma)
head(dataset)
cat("Population Mean (mu):", mu, "\n")
cat("Population Variance (sigma_squared):", sigma_squared, "\n")
sample_mean <- mean(dataset)
sample_variance <- var(dataset)
cat("Sample Mean:", sample_mean, "\n")
cat("Sample Variance:", sample_variance, "\n")
```

**(b)**

```{r}
# σ_n^
sigma2_n <- mean((dataset - sample_mean)^2)

# σ_{n-1}^2
sigma2_n1 <- sum((dataset - sample_mean)^2) / (n - 1)

cat("sigma2_n   =", sigma2_n,  "\n")
cat("sigma2_n-1 =", sigma2_n1, "\n")

```

**(c)**

```{r}
bias_sigma_n   <- sigma2_n  - sigma_squared
bias_sigma_n1  <- sigma2_n1 - sigma_squared

cat("Bias(sigma_n^2)   =", bias_sigma_n,  "\n")
cat("Bias(sigma_n-1^2) =", bias_sigma_n1, "\n")

```

**(d)**\
As the sample size *n* increases, both estimators become more stable and approach the true population variance.\
This behavior is totally expected due to the law of large numbers.\
Here are some graphs that show the change of the bias value the bigger the dataset is:

```{r}
set.seed(42)

# true variance
sigma2_true <- 4
sigma <- sqrt(sigma2_true)
mu <- 10

# sample sizes
ns <- c(10, 20, 50, 100, 200, 500, 1000)

# number of simulations
S <- 5000

bias_n <- numeric(length(ns))
bias_n1 <- numeric(length(ns))

for (i in seq_along(ns)) {
  n <- ns[i]
  
  # simulate S samples of size n
  X <- matrix(rnorm(S * n, mean = mu, sd = sigma), nrow = S)
  
  means <- rowMeans(X)
  
  # biased estimator: divide by n
  sigma2_n <- rowMeans((X - means)^2)
  
  # unbiased estimator: divide by n - 1
  sigma2_n1 <- rowSums((X - means)^2) / (n - 1)
  
  bias_n[i]  <- mean(sigma2_n  - sigma2_true)
  bias_n1[i] <- mean(sigma2_n1 - sigma2_true)
}

# plot
plot(
  ns, bias_n, type = "o", pch = 16, col = "orange",
  xlab = "Sample size n", ylab = "Bias",
  main = "Bias of Variance Estimators vs Sample Size",
  ylim = range(c(bias_n, bias_n1, 0))
)
lines(ns, bias_n1, type = "o", pch = 16, col = "steelblue")

abline(h = 0, lty = 2)

```

**(e) and (f)**

Assume that $X_1, \dots, X_n$ are i.i.d. random variables with $$
\mathbb{E}[X_i] = \mu, \qquad \mathrm{Var}(X_i) = \sigma^2,
$$ and let $$
\bar X = \frac{1}{n}\sum_{i=1}^n X_i
$$ be the sample mean.

We consider two estimators of the population variance $\sigma^2$: $$
\sigma_n^2   = \frac{1}{n}   \sum_{i=1}^n (X_i - \bar X)^2,
\qquad
\sigma_{n-1}^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar X)^2.
$$

#### Step 1: Compute $\mathbb{E}\!\left[\sum_{i=1}^n (X_i - \bar X)^2\right]$

First we use the identity $$
\sum_{i=1}^n (X_i - \bar X)^2
= \sum_{i=1}^n X_i^2 - n \bar X^2.
$$

Taking expectations: $$
\mathbb{E}\left[\sum_{i=1}^n (X_i - \bar X)^2\right]
= \mathbb{E}\left[\sum_{i=1}^n X_i^2\right] - n\,\mathbb{E}[\bar X^2].
$$

For each $X_i$, $$
\mathbb{E}[X_i^2] = \mathrm{Var}(X_i) + (\mathbb{E}[X_i])^2
= \sigma^2 + \mu^2,
$$ hence $$
\mathbb{E}\left[\sum_{i=1}^n X_i^2\right]
= n(\sigma^2 + \mu^2).
$$

$$
\bar X = \frac{1}{n}\sum_{i=1}^n X_i,
\quad
\mathbb{E}[\bar X] = \mu,
\quad
\mathrm{Var}(\bar X) = \frac{\sigma^2}{n}.
$$ Therefore $$
\mathbb{E}[\bar X^2]
= \mathrm{Var}(\bar X) + (\mathbb{E}[\bar X])^2
= \frac{\sigma^2}{n} + \mu^2.
$$

$$
\begin{aligned}
\mathbb{E}\left[\sum_{i=1}^n (X_i - \bar X)^2\right]
&= n(\sigma^2 + \mu^2)
   - n\left(\frac{\sigma^2}{n} + \mu^2\right) \\
&= n\sigma^2 + n\mu^2 - \sigma^2 - n\mu^2 \\
&= (n-1)\sigma^2.
\end{aligned}
$$

Thus we have the key result: $$
\boxed{
\mathbb{E}\left[\sum_{i=1}^n (X_i - \bar X)^2\right]
= (n-1)\sigma^2
}.
$$

#### Step 2: Expected value of $\sigma_n^2$

By definition, $$
\sigma_n^2 = \frac{1}{n} \sum_{i=1}^n (X_i - \bar X)^2.
$$

$$
\mathbb{E}[\sigma_n^2]
= \frac{1}{n}\,
  \mathbb{E}\left[\sum_{i=1}^n (X_i - \bar X)^2\right]
= \frac{1}{n}\,(n-1)\sigma^2
= \frac{n-1}{n}\,\sigma^2.
$$

$$
\boxed{
\mathbb{E}[\sigma_n^2]
= \left(1 - \frac{1}{n}\right)\sigma^2
}.
$$

The bias of this estimator is $$
\mathrm{Bias}(\sigma_n^2)
= \mathbb{E}[\sigma_n^2] - \sigma^2
= \left(\frac{n-1}{n} - 1\right)\sigma^2
= -\frac{\sigma^2}{n} < 0.
$$

So $\sigma_n^2$ is a **biased** estimator.

#### Step 3: Expected value of $\sigma_{n-1}^2$

$$
\sigma_{n-1}^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar X)^2.
$$

$$
\mathbb{E}[\sigma_{n-1}^2]
= \frac{1}{n-1}\,
  \mathbb{E}\left[\sum_{i=1}^n (X_i - \bar X)^2\right]
= \frac{1}{n-1} \,(n-1)\sigma^2
= \sigma^2.
$$

$$
\boxed{
\mathbb{E}[\sigma_{n-1}^2] = \sigma^2
}.
$$

Therefore the bias of $\sigma_{n-1}^2$ is $$
\mathrm{Bias}(\sigma_{n-1}^2)
= \mathbb{E}[\sigma_{n-1}^2] - \sigma^2
= 0,
$$ so this estimator is **unbiased**.

#### Conclusion

-   The estimator $$
    \sigma_n^2 = \frac{1}{n} \sum_{i=1}^n (X_i - \bar X)^2
    $$ has $\mathbb{E}[\sigma_n^2] = \dfrac{n-1}{n}\sigma^2$, so it is biased with $\mathrm{Bias}(\sigma_n^2) = -\dfrac{\sigma^2}{n}$.

-   The estimator $$
    \sigma_{n-1}^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar X)^2
    $$ satisfies $\mathbb{E}[\sigma_{n-1}^2] = \sigma^2$.
